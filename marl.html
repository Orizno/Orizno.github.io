<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>NTIC RL - MARL</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Reinforcement Learning</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Définition RL</a></li>
							<li><a href="adve.html">Adversarial attacks</a></li>
							<li class="active"><a href="marl.html">Multi-agent RL</a></li>
							<li><a href="meta.html">Meta-learning</a></li>
							<li><a href="sqli.html">Injections SQL</a></li>

						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<article class="post featured">
								<header class="major">
									<h2><a href="#">Multi-agent<br />
									Reinforcement Learning</a></h2>
								</header>
								<p> <a href="#" class="image main"><img src="https://miro.medium.com/max/3000/1*PqoJzG3aX9MXAd_cxf2OTQ.png" alt="Principe du MARL" /></a>
								Source image : <a href="https://medium.com/@RemiStudios/multi-agent-reinforcement-learning-3f00b561f5f0">medium.com</a></p>
								
								<p>Le principe du Reinforcement Learning présenté au dessus est celui du Reinforcement Learning avec un seul agent qui interagit avec l’environnement. Cela peut être utile dans certaines situations (par exemple, si on veut résoudre un labyrinthe par Reinforcement Learning, on n’a besoin que d’un seul agent), mais dans de nombreux cas, on veut pouvoir apprendre plusieurs agents différents, qui peuvent collaborer ou être en compétition, selon l’application. C’est beaucoup plus compliqué que du Reinforcement Learning à un seul agent, puisque tous les agents interagissent simultanément avec l’environnement, ce qui fait qu’en plus de devoir tenir compte de leur état et de l’environnement, ils doivent aussi pour être efficace en quelque sorte anticiper les actions des autres agents.</p>
								<p>Une autre problématique importante du Multi-agent Reinforcement Learning est la sécurité. Un certain nombre d’applications du Multi-agent Reinforcement Learning sont safety-critical, c’est-à-dire qu’il y a certains états que ne peuvent pas prendre les agents les uns envers les autres sous peine de conséquences graves. Par exemple, dans le cas des voitures autonomes, si on considère chaque voiture comme un agent, il ne faut pas qu’elles se retrouvent au même endroit au même moment, sinon il y aura un accident. C’est donc quelque chose de très important d’être sûr que ces états non sûrs ne seront jamais pris par les agents, dans l’apprentissage comme durant les tests. Les deux publications que j’ai lue sur ce sujet cherchaient donc à résoudre ce problème, de deux manières différentes..</p>
								
								<p><a href="#" class="image main"><img src="https://i.imgur.com/hc8OybM.png" alt="Shielding" /></a>
								Source image : <a href="https://arxiv.org/pdf/2101.11196v1.pdf">Safe Multi-Agent Reinforcement Learning via Shielding</a></p>
								
								<p>Je ne vais pas rentrer dans les détails, mais globalement pour l’une des deux manières, ils rajoutent un bouclier entre les agents et l’environnement, qui vérifie que les actions vérifient bien les critères de sécurité, qui sont précisé à l’avance, et si ce n’est pas le cas, il modifie l’action non safe, et renvoie une récompense négative à l’agent ayant essayé de la réaliser, pour qu’il apprenne à ne plus faire d’action non safe.</p>
								<p>L’autre manière est plus abstraite, je n’ai pas encore vraiment recherché pour l’instant à essayer de la comprendre, mais dans les deux cas, cela permet d’éviter les états non safe dans le Multi-agent Reinforcement Learning, donc cela peut être une belle avancée dans le domaine du Reinforcement Learning, par exemple dans les domaines de la voiture autonome et de la robotique.</p>
								
								<h3>Bibliographie</h3>
								<p>[1]</p>
								
							</article>


					</div>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>